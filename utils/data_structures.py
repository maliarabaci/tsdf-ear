import os
import numpy as np
from enum import Enum
from collections import Counter

class eFusion_Weight_Mode(Enum):
    swm = 1,
    dwm = 2,
    swm_dwm = 3

class stream_type(Enum):
    rgb = 1,
    flow = 2,
    audio = 3,
    rgbflow = 4,
    rgbaudio = 5,
    flowaudio = 6,
    rgbflowaudio = 7


class feat_type(Enum):
    single = 1,
    fused = 2


class feat_fusion_type(Enum):
    append = 1,
    feat_max = 2,
    feat_mean = 3,
    feat_add = 4, 
    cbp = 5

class scaler_type(Enum):
    standardscaler = 1,
    minmax = 2,
    robustscaler = 3,
    maxabsscale = 4,
    normalizer = 5,
    powertransformer = 6


class feat_fusion_level(Enum):
    segment = 1,
    video = 2

class model_type(Enum):
    arm = 1,
    stacking = 2,
    swm = 3,
    dwm = 4

class swm_weight_type(Enum):
    class_based = 1,
    sample_based = 2

class network_type(Enum):
    ARN = 1,
    SWM = 2,
    CBP = 3,
    DWM = 4,
    FEAT = 5

class process_phase(Enum):
    train = 1,
    validation = 2,
    test = 3

class optimizer_type(Enum):
    adam = 1,
    sgd = 2,
    lbfgs = 3

# ideal_case: means the target classes are known and 
# the test samples are weighted wrt the class confidences of correct labels
class attention_type(Enum):
    equal_weights = 1,                  # All  classes-samples are weighted equally for different modalities (No attention network)
    manual_weights_classbased = 2,      # All class weights are specified manually through modalities (No attention network)
    ideal_weights_samplebased = 3,      # Test labels are used to specify the class weights (No attention network)
    model_based_weighing = 4,           # Stream or decision weights are generated by pre-trained models (Stream or decision based models are trained with the sample weights calculated from validation set)

class norm_type(Enum):
    class_based = 0,
    sample_based = 1

class weighing_strategy:
    swm = 1,
    dwm = 2,
    swm_dwm = 3 

class label_results:
    def __init__(self):
        self.gt_target_arr_vid_based = np.array([], dtype=np.int32)
        self.pred_arr_vid_based = np.array([], dtype=np.int32)
        self.gt_target_arr_seg_based = np.array([], dtype=np.int32)
        self.pred_arr_seg_based = np.array([], dtype=np.int32)



def get_split_files(str_folder, str_modality, split_id):

    train_setting_file = "train_" + str_modality + "_split%d.txt" % (split_id)
    train_split_file = os.path.join(str_folder, train_setting_file)
    val_setting_file = "val_" + str_modality + "_split%d.txt" % (split_id)
    val_split_file = os.path.join(str_folder, val_setting_file)
    test_setting_file = "test_" + str_modality + "_split%d.txt" % (split_id)
    test_split_file = os.path.join(str_folder, test_setting_file)

    if not os.path.exists(train_split_file) or not os.path.exists(val_split_file) or not os.path.exists(test_split_file):
        print("No split file exists in %s directory. Preprocess the dataset first" % (str_folder))

    return train_split_file, val_split_file, test_split_file

class PerformanceStats:
    def __init__(self, nof_class):
        dict_segment_stats = {'TT':0, 'TF':0, 'FT':0, 'FF':0}
        dict_vid_stats = {'TT':0, 'TF':0, 'FT':0, 'FF':0}
        
        self.segment_hist = np.zeros((nof_class, 4), dtype=np.int32)
        self.vid_hist = np.zeros((nof_class, 4), dtype=np.int32)
        self.segment_transition_counter = Counter(dict_segment_stats)
        self.vid_transition_counter = Counter(dict_vid_stats)

    def update(self, seg_hist, video_hist, seg_transitions, vid_transitions):
        self.segment_hist += seg_hist
        self.vid_hist += video_hist
        self.segment_transition_counter += seg_transitions
        self.vid_transition_counter += vid_transitions

    def get_segment_hist(self):
        return self.segment_hist

    def get_vid_hist(self):
        return self.vid_hist

    def get_segment_transitions(self):
        return self.segment_transition_counter

    def get_vid_transitions(self):
        return self.vid_transition_counter


class SegVidLabels:
    def __init__(self):
        self.segment_label = []
        self.segment_label_gt = []
        self.vid_label_prob = []
        self.vid_label_majority = []
        self.vid_label_gt = []
        
    def update(self, seg_label, vid_label_prob, vid_label_majority, seg_label_gt, vid_label_gt):
        self.segment_label.extend(seg_label)
        self.segment_label_gt.extend(seg_label_gt)
        self.vid_label_prob.append(vid_label_prob)
        self.vid_label_majority.append(vid_label_majority)
        self.vid_label_gt.append(vid_label_gt)

    def get_vid_label_gt(self):
        return self.vid_label_gt

    def get_vid_label_mv(self):
        return self.vid_label_majority

    def get_vid_label_prob(self):
        return self.vid_label_prob

    def get_seg_label(self):
        return self.segment_label

    def get_seg_label_gt(self):
        return self.segment_label_gt


class EvaluationResults:
    def __init__(self, vid_acc, vid_f1score, seg_acc, seg_f1score, conf_mat_vid, conf_mat_seg):
        self.vid_acc = vid_acc
        self.vid_f1score = vid_f1score
        self.seg_acc = seg_acc
        self.seg_f1score = seg_f1score
        self.conf_mat_vid = conf_mat_vid
        self.conf_mat_seg = conf_mat_seg
    
    def get_seg_acc(self):
        return self.seg_acc

    def get_seg_f1score(self):
        return self.seg_f1score

    def get_vid_acc(self):
        return self.vid_acc

    def get_vid_f1score(self):
        return self.vid_f1score

    def get_seg_confmat(self):
        return self.conf_mat_seg

    def get_vid_confmat(self):
        return self.conf_mat_vid